{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":963,"status":"ok","timestamp":1683496761793,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"mF1QtOEB5d1e","outputId":"c2e99568-ce08-407f-93ca-bf3cebdbd966"},"outputs":[{"name":"stdout","output_type":"stream","text":["you are using a Mac-based GPU\n"]}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim.lr_scheduler as lr_scheduler\n","import torch.nn.functional as F\n","\n","if torch.backends.mps.is_available():\n","    device = torch.device('mps')\n","    print( f'you are using a Mac-based GPU' )\n","elif torch.cuda().is_available():\n","    device = torch.cuda.device(0)\n","    print( 'You are using a '+str(torch.cuda.get_device_name(0)) )\n","else: \n","    device = torch.device('cpu')\n","    print( f'you are using a: {device}' )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import the dataset\n","---"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6237,"status":"ok","timestamp":1683496773188,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"7iuRXK8X-nGE","outputId":"e028e89a-77ff-4e60-9610-c43256f64068"},"outputs":[],"source":["#@title 1. Import the dataset\n","from utils import *\n","\n","task = 'cifar10'\n","if task =='cifar10':\n","    num_classes = 10\n","if task =='cifar100':\n","    num_classes = 100\n","batch_size = 128\n","image_size = 32\n","\n","train_loader, test_loader = generate_dataset( task=task, train_batch_size=batch_size, test_batch_size=batch_size, image_size=image_size )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import the Model\n","---"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":365,"status":"ok","timestamp":1683496797345,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"ub4mWGkyDIJp"},"outputs":[],"source":["from utils_mobilenet_v2 import mobilenet_v2_noise as mobilenet_v2\n","from utils_mobilenet_v2 import MobileNetV2\n","from models_utils import Linear\n","\n","def get_model( weights='IMAGENET1K_V2', out_features=10, noise_inference=False, noise_inference_bn=False, \n","               noise_sd=0.05, width_mult=0.4, inverted_residual_setting=None ):\n","    '''Function that imports a MobileNetV2 model, with the option of loading the pre-trained parameters\n","    weights : if None, it will initialize the parameters from scratch, otherwise use \"IMAGENET1K_V2\" for good performance\n","    out_features : the size of the output layer\n","    noise_inference : activates STE when True\n","    noise_sd : the amount of noise for the STE\n","    '''\n","    if weights == 'IMAGENET1K_V2' or weights == 'IMAGENET1K_V1' :\n","        model = mobilenet_v2( weights=weights, noise_inference=noise_inference, noise_inference_bn=noise_inference_bn, noise_sd=noise_sd )\n","    elif weights == 'cifar_specs':\n","        inverted_residual_setting = [\n","                # t, c, n, s\n","                [1, 16, 1, 1],\n","                [6, 24, 2, 1],\n","                [6, 32, 3, 1],\n","                [6, 64, 4, 2],\n","                [6, 96, 3, 1],\n","                [6, 160, 3, 2],\n","                [6, 320, 1, 1],\n","            ]\n","        model = MobileNetV2( num_classes=out_features, width_mult=width_mult, \n","                             noise_inference=noise_inference, noise_inference_bn=noise_inference_bn, noise_sd=noise_sd, inverted_residual_setting=inverted_residual_setting )\n","    elif weights == 'cifar_specs_shallow':\n","        inverted_residual_setting = [\n","                # t, c, n, s\n","                [1, 16, 1, 1],\n","                #[6, 24, 2, 1],\n","                [6, 32, 3, 1],\n","                #[6, 64, 4, 2],\n","                [6, 96, 3, 1],\n","                #[6, 160, 3, 2],\n","                [6, 320, 1, 1],\n","            ]\n","        model = MobileNetV2( num_classes=out_features, width_mult=0.4, \n","                             noise_inference=noise_inference, noise_inference_bn=noise_inference_bn, noise_sd=noise_sd, inverted_residual_setting=inverted_residual_setting )\n","    else:\n","        model = mobilenet_v2( weights=None, noise_inference=noise_inference, noise_inference_bn=noise_inference_bn, noise_sd=noise_sd )\n","    model.classifier[1] = Linear( in_features=model.classifier[1].in_features, out_features=out_features, \n","                                   noise_inference=noise_inference, noise_sd=noise_sd )\n","    model.classifier[0].p = 0.2 ### IT WAS 0.0 BEFORE\n","    return model\n","\n","#model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=True, noise_inference_bn=True )"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter count: 502538\n"]}],"source":["def get_tot_model_params(model, verbose=True):\n","    tot_params = 0\n","    params = []\n","    for p in model.parameters():\n","        params.append( p )\n","        tot_params += ( len( p.flatten() ) )\n","    if verbose: print( f'Parameter count: {tot_params}' )\n","    return tot_params\n","\n","model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=True, width_mult=0.4, noise_inference_bn=False )\n","_ = get_tot_model_params( model )"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683382855323,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"jgiuOxXcbqC4","outputId":"78e694fc-012a-4523-a44e-6381a6e16c11"},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Dropout(p=0.0, inplace=False)\n","  (1): Linear(in_features=1280, out_features=10, bias=True, noise_inference=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model.classifier"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1683496807026,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"ud3svxK2RKpJ"},"outputs":[],"source":["### this can go as I have put it on utils.py\n","\n","def training_algo( training_type, model, data_loaders, optimizer=None, criterion=None, scheduler=None, out_activation=None,\n","                   device='cpu', lr=1e-3, clip_w=2.5, epochs=10, epochs_noise=2, \n","                   noise_sd=1e-2, noise_every=100, levels=None, num_levels=15, print_every=1, verbose=False,\n","                   save_checkpoint_path=None, load_checkpoint_path=None  ):\n","\n","    train_loader, test_loader = data_loaders\n","    if criterion is None: criterion = torch.nn.NLLLoss() #torch.nn.CrossEntropyLoss()\n","    if optimizer is None: optimizer = torch.optim.SGD( model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4 )\n","    if scheduler is None: scheduler = torch.optim.lr_scheduler.MultiStepLR( optimizer, milestones=[100, 150, 200], gamma=0.5 )\n","    if out_activation is None: out_activation = torch.nn.LogSoftmax( dim=-1 )\n","\n","    if load_checkpoint_path is not None:\n","        checkpoint = torch.load( load_checkpoint_path, map_location='cpu' )\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        model = model.to(device)\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        epoch_start = checkpoint['epoch']\n","    else:\n","        model = model.to(device)\n","        epoch_start = 0\n","    \n","\n","    losses_train, accs_train = [], []\n","    for e in range(epochs):\n","        losses = []\n","        correct = 0\n","        tot_samples = 0\n","        for batch_idx, (x, y) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            x = x.to(device)\n","            y = y.to(device)\n","            yhat = model( x )\n","            y_soft = out_activation( yhat )\n","            loss = criterion( y_soft, y.long() )\n","            loss.backward()\n","\n","            if training_type == 'qat_noise' or training_type == 'qat':\n","                for p in list(model.parameters()):\n","                        if hasattr(p,'hid'):\n","                            p.data.copy_(p.hid)\n","\n","            optimizer.step()\n","            if scheduler is not None: scheduler.step()\n","            losses.append( loss.item() )\n","            correct += torch.eq( torch.argmax(yhat, dim=1), y ).cpu().sum()\n","            tot_samples += len(y)\n","\n","            if e+1 > epochs - epochs_noise and batch_idx%noise_every==0 and training_type == 'noise_fine_tuning':\n","               with torch.no_grad():\n","                   for p in model.parameters():\n","                       delta_w = torch.abs( p.max()-p.min() )\n","                       n = torch.randn_like( p )*(noise_sd*delta_w)\n","                       p.copy_( p+n )\n","            \n","            if clip_w is not None:\n","                with torch.no_grad():\n","                    for p in model.parameters():\n","                        std_w = torch.std( p )\n","                        p.clip_( -std_w*clip_w, +std_w*clip_w )\n","\n","            if training_type == 'qat':\n","                for p in list(model.parameters()):  # updating the hid attribute\n","                    if hasattr(p,'hid'):\n","                        p.hid.copy_(p.data)\n","                    p.data = quantize( parameters=p.data, levels=levels, num_levels=num_levels, device=device )\n","\n","            if training_type == 'qat_noise':\n","                for p in list(model.parameters()):  # updating the hid attribute\n","                    if hasattr(p,'hid'):\n","                        p.hid.copy_(p.data)\n","                    p.data = quantize( parameters=p.data, levels=levels, num_levels=num_levels, device=device )\n","                    p.data.add_( torch.randn_like(p.data)*noise_sd )\n","\n","        acc_train = correct/tot_samples\n","        loss_train = np.mean(losses)\n","        if verbose and e%print_every==0:\n","            print( f'Train Epoch {e+1}, Train accuracy {acc_train*100:.2f}% Train loss {loss_train:.4f}' )\n","        accs_train.append(acc_train); losses_train.append(loss_train)\n","\n","    if save_checkpoint_path is not None:\n","        torch.save({\n","            'epoch': epochs+epoch_start,\n","            'model_state_dict': model.to('cpu').state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss': loss.item(),\n","            }, save_checkpoint_path.format( epochs+epoch_start+1 ))\n","        print(f'Checkpoint saved at: {save_checkpoint_path}')\n","\n","\n","    losses = []\n","    correct = 0\n","    tot_samples = 0\n","    model = model.to(device).eval()\n","    for x, y in test_loader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        yhat = model( x )\n","        y_soft = out_activation( yhat )\n","        loss = criterion( y_soft, y.long() )\n","        losses.append( loss.item() )\n","        correct += torch.eq( torch.argmax(yhat, dim=1), y ).cpu().sum()\n","        tot_samples += len(y)\n","    acc_test = correct/tot_samples\n","    loss_test = np.mean(losses)\n","    if verbose: print( f'Tot epochs {epochs+epoch_start} -- Test accuracy {acc_test*100:.2f}% Test loss {loss_test:.4f}' )\n","\n","    return model, [accs_train, losses_train], [acc_test, loss_test]\n","\n","\n","def testing( model, test_loader, criterion=None, out_activation=None, device='cpu', verbose=True ):\n","    '''The function assessing the test classification accuracy of the model.\n","    model: model of choice\n","    test_loader: the test dataloader for the task of choice\n","    verbose: if True, makes the function output the test accuracy and loss'''\n","    model = model.to(device).eval()\n","    losses = []\n","    correct, tot_samples = 0, 0\n","    if criterion is None: criterion = torch.nn.NLLLoss()\n","    if out_activation is None: out_activation = torch.nn.LogSoftmax( dim=-1 )\n","    for x, y in test_loader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        yhat = model( x )\n","        y_soft = out_activation( yhat )\n","        loss = criterion( y_soft, y.long() )\n","        losses.append( loss.item() )\n","        correct += torch.eq( torch.argmax(yhat, dim=1), y ).cpu().sum()\n","        tot_samples += len(y)\n","    acc_test = correct/tot_samples\n","    loss_test = np.mean(losses)\n","    if verbose: print( f'-- Test accuracy {acc_test*100:.2f}% Test loss {loss_test:.4f}' )\n","    return acc_test, loss_test\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"po2ftUQmgAP5"},"source":["## CIFAR 10\n","---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### ----> Training"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352853,"status":"ok","timestamp":1683497182953,"user":{"displayName":"Filippo Moro","userId":"06456865509796473041"},"user_tz":-120},"id":"6nfekZKeOsVU","outputId":"fe59c3b2-feb8-47de-98ed-0ef14d92a25f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch 1, Train accuracy 46.77% Train loss 1.4450\n","Checkpoint saved at: /Users/filippomoro/Documents/Training_with_memristors/Models/cifar10_normal_epochs2.pt\n","Tot epochs 2 -- Test accuracy 49.73% Test loss 1.3693\n"]}],"source":["epochs = 1\n","epochs_load = 1\n","lr = 1e-2\n","\n","noise_inference, noise_sd_ste = False, 0.1\n","data_loaders = [train_loader, test_loader] # [trainloader, testloader]\n","#model = get_model(weights='IMAGENET1K_V2', noise_inference=noise_inference, noise_sd=noise_sd_ste, out_features=num_classes)\n","model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=noise_inference, noise_inference_bn=noise_inference, noise_sd=noise_sd_ste )\n","criterion = torch.nn.NLLLoss()\n","optimizer = torch.optim.SGD( model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4 )\n","scheduler = torch.optim.lr_scheduler.MultiStepLR( optimizer, milestones=[100, 150, 200], gamma=0.5 )\n","\n","model_type = {False:'normal', True:'ste{}'}\n","root_path = '/Users/filippomoro/Documents/Training_with_memristors/Models'\n","save_checkpoint_path = root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[noise_inference].format(noise_sd_ste), epochs+epochs_load ) # epochs_load+epochs\n","if epochs_load == 0:\n","    load_checkpoint_path = None\n","else:\n","    load_checkpoint_path = root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[False].format(noise_sd_ste), epochs_load )\n","\n","model_trained, [accs_train, losses_train], [acc_test, loss_test] = training_algo( training_type='normal', model=model, data_loaders=data_loaders,\n","                                                                                criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n","                                                                                clip_w=None, lr=lr, epochs=epochs, epochs_noise=2, \n","                                                                                print_every=1, verbose=True, device=device,\n","                                                                                save_checkpoint_path=save_checkpoint_path,\n","                                                                                load_checkpoint_path=load_checkpoint_path )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### ----> Testing with Noise"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Avg accuracy with noise on params 0.0% is: 88.28%\n","Avg accuracy with noise on params 1.0% is: 88.19%\n","Avg accuracy with noise on params 5.0% is: 87.61%\n","Avg accuracy with noise on params 10.0% is: 84.98%\n","Avg accuracy with noise on params 15.0% is: 75.63%\n","Avg accuracy with noise on params 20.0% is: 52.63%\n"]}],"source":["n_models = 1\n","noise_sd_list = np.array([0, 0.01, 0.05, 0.1, 0.15, 0.2]) #np.array([0, 0.01, 0.02, 0.04, 0.05, 0.07, 0.1, 0.15])\n","# noise_sd_list = np.array([0]) \n","acc_test_c10_normal = np.zeros( (n_models, len(noise_sd_list)) )\n","\n","### model path\n","#path_model = f'/Users/filippomoro/Documents/Training_with_memristors/Models/{task}_normal_virgin.pt'\n","#path_model = f'/Users/filippomoro/Documents/Training_with_memristors/Models/{task}_ste_{0.05}_adam.pt'\n","root_path = '/Users/filippomoro/Documents/Training_with_memristors/Models'\n","model_type = {False:'normal', True:'ste{}'}\n","save_checkpoint_path = None #root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[noise_inference], epochs_load+epochs )\n","load_checkpoint_path = root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[True].format(0.1), 10 )\n","\n","with torch.no_grad():\n","    for n, noise_sd in enumerate(noise_sd_list):\n","        for m in range( n_models ):\n","            model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=True, noise_sd=noise_sd )\n","            checkpoint = torch.load( load_checkpoint_path, map_location='cpu' )\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            model = model.to(device)\n","            model.eval()\n","\n","            acc_test_noise, loss_test_noise = testing( model=model, test_loader=test_loader, device=device, verbose=False )\n","            acc_test_c10_normal[m, n] = acc_test_noise\n","        print( f'Avg accuracy with noise on params {noise_sd*100}% is: {acc_test_c10_normal[:,n].mean()*100:.2f}%' )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ymHBgx49gXr5"},"source":["### CIFAR 100\n","---"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch 1, Train accuracy 81.99% Train loss 0.5888\n","Tot epochs 101 -- Test accuracy 64.92% Test loss 1.2925\n"]}],"source":["epochs = 1\n","epochs_load = 100\n","lr = 1e-2\n","\n","noise_inference, noise_sd_ste = False, 0.1\n","data_loaders = [train_loader, test_loader] # [trainloader, testloader]\n","#model = get_model(weights='IMAGENET1K_V2', noise_inference=noise_inference, noise_sd=noise_sd_ste, out_features=num_classes)\n","model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=noise_inference, noise_inference_bn=noise_inference, noise_sd=noise_sd_ste )\n","criterion = torch.nn.NLLLoss() #torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD( model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4 )\n","scheduler = torch.optim.lr_scheduler.MultiStepLR( optimizer, milestones=[100, 150, 200], gamma=0.5 )\n","\n","model_type = {False:'normal', True:'ste{}'}\n","root_path = '/Users/filippomoro/Documents/Training_with_memristors/Models'\n","save_checkpoint_path = None #root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[noise_inference].format(noise_sd_ste), epochs+epochs_load ) # epochs_load+epochs\n","load_checkpoint_path = root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[False].format(noise_sd_ste), epochs_load )\n","\n","model_trained, [accs_train, losses_train], [acc_test, loss_test] = training_algo( training_type='normal', model=model, data_loaders=data_loaders,\n","                                                                                criterion=criterion, optimizer=optimizer,\n","                                                                                clip_w=None, lr=lr, epochs=epochs, epochs_noise=2, \n","                                                                                print_every=1, verbose=True, device=device,\n","                                                                                save_checkpoint_path=save_checkpoint_path,\n","                                                                                load_checkpoint_path=load_checkpoint_path )"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Avg accuracy with noise on params 0.0% is: 64.02%\n","Avg accuracy with noise on params 1.0% is: 63.96%\n","Avg accuracy with noise on params 5.0% is: 62.34%\n","Avg accuracy with noise on params 10.0% is: 56.07%\n","Avg accuracy with noise on params 15.0% is: 40.90%\n","Avg accuracy with noise on params 20.0% is: 14.99%\n"]}],"source":["n_models = 1\n","noise_sd_list = np.array([0, 0.01, 0.05, 0.1, 0.15, 0.2]) #np.array([0, 0.01, 0.02, 0.04, 0.05, 0.07, 0.1, 0.15])\n","# noise_sd_list = np.array([0]) \n","acc_test_c10_normal = np.zeros( (n_models, len(noise_sd_list)) )\n","\n","### model path\n","#path_model = f'/Users/filippomoro/Documents/Training_with_memristors/Models/{task}_normal_virgin.pt'\n","#path_model = f'/Users/filippomoro/Documents/Training_with_memristors/Models/{task}_ste_{0.05}_adam.pt'\n","root_path = '/Users/filippomoro/Documents/Training_with_memristors/Models'\n","model_type = {False:'normal', True:'ste{}'}\n","save_checkpoint_path = None #root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[noise_inference], epochs_load+epochs )\n","load_checkpoint_path = root_path + '/{}_{}_epochs{}.pt'.format( task, model_type[True].format(0.1), 110 )\n","\n","with torch.no_grad():\n","    for n, noise_sd in enumerate(noise_sd_list):\n","        for m in range( n_models ):\n","            model = get_model( weights = 'cifar_specs', out_features=num_classes, noise_inference=True, noise_sd=noise_sd )\n","            checkpoint = torch.load( load_checkpoint_path, map_location='cpu' )\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            model = model.to(device)\n","            model.eval()\n","\n","            acc_test_noise, loss_test_noise = testing( model=model, test_loader=test_loader, device=device, verbose=False )\n","            acc_test_c10_normal[m, n] = acc_test_noise\n","        print( f'Avg accuracy with noise on params {noise_sd*100}% is: {acc_test_c10_normal[:,n].mean()*100:.2f}%' )"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOzRtykGZS8zJilPYKuMq2R","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
